 {
    "Rack Sensor Max Temperature Over Time": {
        "prereqs": [
            {
                "test": "| inputlookup physical_environmental | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp properly.",
            "Convert our timestamp to a true timestamp format.",
            "Assign our temperature field as temperature in F (Sorry rest of the world ;)",
            "Chart our maximum temperatures over time.."
             ],
        "value": "| inputlookup physical_environmental \n| eval _time=strptime(dateTime, \"%Y/%m/%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| eval tempF=sensorValue  \n| timechart fixedrange=false max(tempF) as maxTempF",
        "label": "Rack Sensor Max Temperature Over Time"
    },

    "Rack Sensor Temperature Trending by Rack Sensors": {
        "prereqs": [
            {
                "test": "| inputlookup physical_environmental | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp properly.",
            "Convert our timestamp to a true timestamp format.",
            "Use regex to extract Room Row Rack and Sensor information from the SensorLocation field.",
            "Reasseble a Location value with the fields we just extracted and also create a tempF field.",
            "Only keep the fields that are interesting.",
            "Search for a specific Sensor OR Rack location.",
            "Create a field called sensor that is formatted with the row number rack and sensor location.",
            "Run this through timechart to get our average temperature value. Use fixedrange false since this is populated from a lookup."
                    ],
        "value": "| inputlookup physical_environmental \n| eval _time=strptime(dateTime, \"%Y/%m/%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| rex field=sensorLocation \"(Room(?<Room>[^\\-]+)-Row(?<Row>[^-]+)-Rack(?<Rack>[^-]+)-(?<Sensor>[^-]+))\" \n| eval Location=Room.\"-\".Row.\":\".Rack.\"-\".Sensor, tempF=sensorValue \n| fields _time Sensor tempF Row Rack \n| search Sensor=* OR Rack=* \n| eval Sensor=Row.Rack.\"-\".Sensor \n| timechart span=1m fixedrange=false avg(tempF) AS AverageTempF by Sensor",
        "label": "Rack Sensor Temperature Trending by Rack Sensors"
    },
    
    "O2A - Estimated Daily Revenue": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Append our historic revenue.",
            "Rename fields we are going to return to the base search.",
            "Fields we're going to return to the base search.",
            "Fix our timestamp field.",
            "Enrich our results by adding a price field based on the Product / SKU.",
            "Use timechart to sum our total sold and trend it."
                    ],
        "value": "| inputlookup prepaid_o2a_logs \n| append [ inputlookup prepaid_previous_revenue \n| rename date AS timestamp totalRevenue AS price \n| fields timestamp price ] \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| lookup prepaid_o2a_products productSKU OUTPUT price \n| timechart fixedrange=false sum(price) AS totalSold",
        "label": "O2A - Estimated Daily Revenue"
    },

    "O2A - Estimated Revenue by Location": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",   
            "Fix our timestamp field.",
            "Enrich our results by adding a price field based on the Product / SKU.",
            "Choose only our interesting fields.",
            "Search for only successful transactions.",
            "Enrich our results by adding location information.",
            "Use timechart to sum our total sold by location."
                    ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| lookup prepaid_o2a_products productSKU OUTPUT price \n| fields _time orderLocation transactionStatus price transactionStatus \n| search transactionStatus=\"SUCCESS\" \n| lookup prepaid_locations orderLocation \n| timechart fixedrange=false span=1h sum(price) by description",
        "label": "O2A - Estimated Revenue by Location"
    },

    "O2A - Estimated Revenue Lost due to Sytem Problems": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",   
            "Fix our timestamp field.",
            "Enrich our results by adding a price field based on the Product / SKU.",
            "Choose only our interesting fields.",
            "Search for only successful transactions.",
            "Enrich our results by adding location information.",
            "Use timechart to sum our total sold by location."
                    ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| lookup prepaid_o2a_products productSKU OUTPUT price \n| fields _time orderLocation transactionStatus price transactionStatus \n| search transactionStatus=\"FAIL\" \n| lookup prepaid_locations orderLocation \n| timechart fixedrange=false span=1d sum(price)",
        "label": "O2A - Estimated Revenue Lost due to Sytem Problems"
    },

    "02A Compliance Reporting - Potential SIM Abuse": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Fix our timestamp from our lookup.",
            "Convert our timestamp to a recognized timestamp format..",
            "Search for our failed processes.",
            "Only use the field(s) we want..",
            "Enrich our error messages with more human friendly details.",
            "Search for our SIM Activation Error Message..",
            "Add location data to our search results.",
            "Calculate our counts of Orders and Location based on the CustomerID",
            ""
                    ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| search p3Status=\"FAIL\" \n| fields _time p3* customer* order* \n| lookup prepaid_mobile_errors pMessage AS p3Message \n| search p3Message=\"ERROR-B993\" \n| lookup prepaid_locations orderLocation OUTPUT description \n| stats count values(customerIdNumber) AS customerIdNumber values(orderTracking) AS orderTracking values(pDetails) as Details list(description) AS Location by customerID \n| sort - count",
        "label": "02A Compliance Reporting - Potential SIM Abuse"
    },

    "02A Provisioning Errors by Customer ID": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Fix our timestamp from our lookup.",
            "Convert our timestamp to a recognized timestamp format..",
            "Enrich our orderlocation with a lookup that contains geodata.",
            "Search for failed events in our O2A process.",
            "Only use the field(s) we want..",
            "Enrich our error messages with more human friendly details.",
            "Calculate our values of errors, customerIDs, and Orders by our Customer ID.",
            "Sort on the count.",
            "Make our fields more friendly for a report view.",
            "Reorder our fields in a more readable and understandable way."
                    ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| search p3Status=\"FAIL\" \n| fields _time p3* customer* order* \n| lookup prepaid_mobile_errors pMessage AS p3Message \n| stats count values(pDetails) AS \"Error Details\" values(customerIdNumber) AS \"Customer ID Number\" values(orderTracking) AS \"Order Tracking\" by customerID \n| sort - count \n| rename count AS Count customerID AS \"Customer ID\" \n| fields \"Customer ID\" \"Customer ID Number\" \"Error Details\" \"Order Tracking\" Count",
        "label": "02A Provisioning Errors by Customer ID"
    },

    "02A Geomapping of Orders by Count": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Only use the field(s) we want..",
            "Enrich our orderlocation with a lookup that contains geodata.",
            "Use geostats to map this data out specifying the lat and long fields. We also adjust the bin size to get finer resolution of the locations."
        ],
        "value": "| inputlookup prepaid_o2a_logs \n| fields orderLocation \n| lookup prepaid_locations orderLocation \n| geostats count latfield=lat longfield=lon binspanlat=19 binspanlong=19",
        "label": "02A Geomapping of Orders by Count"
    },

    "02A Top New Prepaid Purchasing Countries": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Only use the field(s) we want..",
            "Enrich our orderlocation with a lookup that contains geodata.",
            "Use geostats to map this data out specifying the lat and long fields. We also adjust the bin size to get finer resolution of the locations."
        ],
        "value": "| inputlookup prepaid_o2a_logs \n| fields iDCountry orderType \n| search orderType=\"NEW\" \n| eval iDCountry=upper(iDCountry) \n| top iDCountry",
        "label": "02A Top New Prepaid Purchasing Countries"
    },
    
    "O2A Timechart of Ordertypes": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp properly.",
            "Convert our timestamp to a true timestamp format.",
            "Only use the field(s) we want..",
            "Search for all Order Types (New and TopUp).",
            "Timechart these with a stacked visualization. Also use fixedrange=false since this is a lookup table.."
        ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| fields _time orderType orderLocation IdType customerIdNumber \n| search orderType=\"*\" \n| timechart fixedrange=false span=30m count by orderType ",
        "label": "O2A Timechart of Ordertypes"
    },

    "O2A Top Selling Packages": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Only use the field(s) we want..",
            "Search for our successful transactions.",
            "Enrich these results with the human friendly description of the Product/SKU",
            "Get our top products."
        ],
        "value": "| inputlookup prepaid_o2a_logs \n| fields _time productSKU transactionStatus \n| search transactionStatus=\"SUCCESS\" \n| lookup prepaid_o2a_products productSKU \n| top description",
        "label": "O2A Top Selling Packages"
    },
    
    "O2A End-To-End Transactional Status Overtime": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp properly.",
            "Convert our timestamp to a true timestamp format.",
            "Only use the field(s) we want..",
            "Search for all Order Types (New and TopUp).",
            "Timechart these with a stacked visualization. Also use fixedrange=false since this is a lookup table.."
        ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| fields _time transactionStatus \n| timechart span=10m fixedrange=false count by transactionStatus",
        "label": "O2A End-To-End Transactional Status Overtime"
    },

    "02A By Process Errors over Time": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp properly.",
            "Convert our timestamp to a true timestamp format.",
            "Only use the field(s) we want..",
            "Create a numeric value for the order status.. Ok is 0, and anything else is 1.",
            "Use eventstats to create a running total of our status counts.",
            "Create a timechart with a 10minute span of the sum of our per process counts and name the processess. Use fixedrange true because this is a lookup."
        ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| fields _time p1* p2* p3* p4* \n| eval p1=case(p1Status==\"OK\",0,1=1,\"1\"), p2=case(p2Status==\"OK\",0,1=1,\"1\"), p3=case(p3Status==\"OK\",0,1=1,\"1\"),p4=case(p4Status==\"OK\",0,1=1,\"1\") \n| eventstats sum(p1) AS p1cnt sum(p2) AS p2cnt sum(p3) AS p3cnt sum(p4) AS p4cnt by _time \n| timechart fixedrange=false span=10m sum(p1cnt) AS \"Billing Systems\" sum(p2cnt) as \"Fullfilment\" sum(p3cnt) AS \"Service Activation\" sum(p4cnt) AS \"CRM\"",
        "label": "02A By Process Errors over Time"
    },

    "Provisioning and Activation Errors by Type": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp properly.",
            "Convert our timestamp to a true timestamp format.",
            "Searching in our Service Activation Process for failures.",
            "Only use the field(s) we want..",
            "Enrich our error messages with more Human Readable data.",
            "Get values for our individual error messages and details by time.",
            "Search for where we have a count > 0",
            "Run this through stats again to get a count by Error Message.",
            "Use xyseries here to create a chartable view of our Error Details by Error Message."
                    ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| search p3Status=\"FAIL\" \n| fields _time p3* customer* \n| lookup prepaid_mobile_errors pMessage AS p3Message \n| stats count values(pDetails) AS \"FailureReason\" values(p3Message) AS \"ErrorMessage\" by _time \n| search count > 0 \n| stats sum(count) AS count by FailureReason ErrorMessage \n| xyseries   ErrorMessage FailureReason count",
        "label": "Provisioning and Activation Errors by Type"
    },
    
    "O2A - Retail Staffing Issues": {
        "prereqs": [
            {
                "test": "| inputlookup prepaid_o2a_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp properly.",
            "Narrow our fields down to those of interest.",
            "Enrich our event messages with location data.",
            "Search for a specific retail locaton.",
            "Sort our date by time.",
            "Use streamstats with window=1 to add the previous time stamp to the current event.",
            "Calculate the duration of the event.",
            "Reformat the field.",
            "Look for our transactions under 25 minutes.",
            "Use stats to get values for our events based on description and _time",
            "Search for durations over 5 minutes.",
            "Humanize the fields.",
            "Narrow our fields down.",
            "Use timechart to create a table with a 1 hour span.",
            "Humanize our time field.",
            "Create a tabled format for a report view."
                    ],
        "value": "| inputlookup prepaid_o2a_logs \n| eval _time=strptime(timestamp, \"%Y-%m-%d %H:%M:%S\") \n| fields _time orderLocation orderType productSKU transactionStatus \n| lookup prepaid_locations orderLocation OUTPUT description \n| search description=\"Store1*\" \n| sort 0 _time \n| streamstats window=1 current=false last(_time) AS previousTime \n| eval transactionDuration = ( _time - previousTime ) / 60 \n| eval transactionDuration = round(transactionDuration,2) \n| where transactionDuration < 25 \n| stats values(transactionDuration) as transactionDur values(_time) AS startTime values(orderLocation) AS orderLocation values(orderType) AS orderType values(transactionStatus) AS transactionStatus by description _time \n| where transactionDur > 5 \n| rename description AS \"Location\" transactionDur AS \"Duration\" \n| fields Location Duration _time startTime \n| timechart fixedrange=false span=1h count list(Duration) AS Duration list(startTime) as Times list(Location) AS Location \n| convert ctime(Times) timeformat=\"%Y/%m/%d %H:%M:%S\" \n| table _time Location  Times Duration count",
        "label": "O2A - Retail Staffing Issues"
    },

    "CDN - User Behavior - Top Browsers": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_connections.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Only use the field(s) we want..",
            "Analyze our data set by Browser type now.. ",
            "Here we pull out the OS string and do some matching. This is pretty basic. There are apps on SplunkBase that do a better job.",
            "Here we pull out the browser type. Again this is pretty basic and now where complete. There are apps for this...",
            "Same here, but for arch type..",
            "Make the search results a bit prettier..",
            "And find our browsers.."
        ],
        "value": "| inputlookup cdn_connections \n| sort - _time \n| fields _time http_user_agent \n| rename http_user_agent AS useragent \n| eval os = case(match(useragent,\"Windows .. 5.1\"),\"Windows XP\",match(useragent,\"droid\"),\"Android\",match(useragent,\"Windows NT 6.1\"),\"Windows 7\",match(useragent,\"Win98\"),\"Windows 98\",match(useragent,\"Windows NT 6.3\"),\"Windows Server 2012\",match(useragent,\"Windows NT 6.2\"),\"Windows 8\",match(useragent,\"Windows NT 6.0\"),\"Windows Server 2008\",match(useragent,\"Windows Phone 8.1\"),\"Windows Mobile 8\",match(useragent,\"Mac OS X 10.10\"),\"OSX 10.10\",match(useragent,\"Mac OS X 10_9\"),\"OSX 10.9\",match(useragent,\"Mac OS X 10.6\"),\"OSX 10.6\",match(useragent,\"Mac OS X 10.5\"),\"OSX 10.5\",match(useragent,\"Mac OS X 10_8\"),\"OSX 10.8\",match(useragent,\"Mac OS X 10_7\"),\"OSX 10.7\",match(useragent,\"Apple TV\"),\"IOS\",match(useragent,\"iPad\"),\"IOS\",match(useragent,\"iPhone\"),\"IOS\",match(useragent,\"linux|Linux\"),\"Linux\") \n| eval browser = case(match(useragent,\"MSIE 10.0\"),\"IE 10.0\",match(useragent,\"MSIE 7.0\"),\"IE 7.0\",match(useragent,\"Chrome\"),\"Chrome\",match(useragent,\"Safari/\"),\"Safari\",match(useragent,\"Firefox\"),\"Firefox\",match(useragent,\"MSIE 9.0\"),\"IE 9.0\",match(useragent,\"ANVSDK ios\"),\"Anvato Player\",match(useragent,\"UCBrowser\"),\"UC Browser\",match(useragent,\"Opera\"),\"Opera\",match(useragent,\"Gecko Galeon\"),\"Gecko\",match(useragent,\"Netscape6\"),\"Netscape\") \n| eval arch = case(match(useragent,\"droid\"),\"android\",match(useragent,\"iPad\"),\"ipad\",match(useragent,\"iPod\"),\"ipod\",match(useragent,\"Apple TV\"),\"Apple TV\",match(useragent,\"iPhone\"),\"iphone\",match(os,\"Windows\"),\"x86_64\",match(useragent,\"Intel|x86_64\"),\"x86_64\") \n| fillnull value=\"UNKNOWN\" os arch browser \n| stats count by browser \n| sort - count",
        "label": "CDN - User Behavior - Top Browsers"
    },

    "Cache Hit Ratio by Number of Requests": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "Pull our fields of interest from the sourcetype(s)",
            "Start calculating our hit ratio with our messageBytes by time and contentprovider",
            "Calculate total hits and total bytes transferred from our cache",
            "Summate our total requests and cached content values",
            "Calculate a hit ratio of cached content and format it..",
            ""
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| fields _time messageBytes cached cp \n| stats count values(messageBytes) AS totalBytes by _time cp cached \n| stats sum(count) AS totalRequests sum(totalBytes) as totalBytes by cached  \n| stats sum(totalRequests) as totalRequested sum(eval(totalRequests*if(cached==\"true\",1,0))) as \"cached\" \n| eval cacheRequestedHitRatio=round(cached/totalRequested * 100, 2) \n| fields cacheRequestedHitRatio",
        "label": "Cache Hit Ratio by Number of Requests"
    },

    "Cache Hit Ratio by Amount of Traffic": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "Pull our fields of interest from the sourcetype",
            "Start calculating our total bytes and cached bytes content.",
            "Calculate a hit ratio against the cache.",
            "Display our cache hit ratio.",
            ""
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| fields _time messageBytes cached \n| stats sum(messageBytes) as \"totalBytes\", sum(eval(messageBytes * if(cached==\"true\",1,0))) as \"cachedBytes\" \n| eval cacheTrafficHitRatio=round(cachedBytes/totalBytes*100,2) \n| fields cacheTrafficHitRatio",
        "label": "Cache Hit Ratio by Amount of Traffic"
    },

    
    "CDN Total Number of Requests": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "Use stats to count the total number of events.",
            ""
        ],
        "value": "| inputlookup cdn_general_operations \n| eval _time=strptime(_time, \"%Y-%m-%d %H:%M:%S\") \n| stats count",
        "label": "CDN Total Number of Requests"
    },

    "CDN Total Amount of Traffic": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "Pull our fields of interest from the dataset.",
            "Start summating our messagebytes.",
            "Calculate our total traffic in gigabytes.",
            "Display our field with the value.",
            ""
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| fields _time messageBytes \n| stats sum(messageBytes) as totalTrafficBytes \n| eval totalTrafficGBytes=totalTrafficBytes/pow(10,9) \n| fields totalTrafficGBytes",
        "label": "CDN Total Amount of Traffic"
    },


    "CDN Total Number of Errors Over Time": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "Convert our timestamp to this format.",
            "Sort on time and include all results (large lookup.)",
            "Pull our fields of interest..",
            "Anything with a status > 400, we consider failed. Set these to value of 1 / true.",
            "Search for our failed events.",
            "Chart our failed events over time.",
            ""
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| convert timeformat=\"%Y-%m-%d %T\" mktime(_time) AS _time \n| sort 0 _time \n| fields _time status \n| eval statusFailed=if(status >= 400, 1, 0) \n| search statusFailed=\"1\" \n| timechart fixedrange=false span=1m sum(statusFailed) AS \"Error Events\"",    
        "label": "CDN Total Number of Errors Over Time"
    },

    
    "CDN Total Amount of Traffic Transferred Over Time": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "",
            "These are the only fields we are interested in for this search.",
            "Calculate Mbps from the given rate.",
            "Use timechart here with a one minute bucket span and fixedrange false because this is coming from a lookup file."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| convert timeformat=\"%Y-%m-%d %T\" mktime(_time) AS _time \n| sort 0 _time \n| fields _time messageBytes \n| eval trafficMbs=messageBytes/pow(1024,2) \n| timechart span=1m fixedrange=false sum(trafficMbs) as trafficMbs", 
        "label": "CDN Total Amount of Traffic Transferred Over Time"
    },

    "CDN Average Respone Time over Time": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "Sort on time and include all results (large lookups)",
            "These are the only fields we are interested in for this search.",
            "Timechart the average response time, with a 1m span and fixedrange because this is coming from a lookup file.",
            "Format our time for a bit more human readable format."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| sort 0 _time \n| fields _time responseTime \n| timechart fixedrange=false span=1m avg(responseTime) AS avgResponseTime \n| eval avgResponseTime=round(avgResponseTime,3)",
        "label": "CDN Average Respone Time over Time"
    },
    
    "CDN Geostats of Requests by Location": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "",
            "These are the only fields we are interested in for this search.",
            "Use the IPLocation command to enrich our existing requesting IP with Geolocation data.",
            "Use Geostats with the enriched data to get a mapped visualizaton of all our requestors."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval _time=strptime(_time,\"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| sort 0 _time \n| fields _time requestClientIp \n| iplocation requestClientIp \n| geostats count latfield=lat longfield=lon",    
        "label": "CDN Geostats of Requests by Location"
    },
   
    "CDN Average Bandwidth Used Over Time": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "These are the only fields we are interested in for this search.",
            "",
            "Calculate the bandwidth used and convert it to MBps.",
            "Chart our average bandwidth, in 1 minute buckets, over time. We used fixedrange=false since this is data from a lookup."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| convert timeformat=\"%Y-%m-%d %T\" mktime(_time) AS _time \n| fields _time messageBytes netPerfdownloadTime \n| sort 0 _time \n| eval bandwidthUsedMbps = ((messageBytes/netPerfdownloadTime)*1000/1024/128) \n| timechart fixedrange=false span=1m avg(bandwidthUsedMbps) AS avgBandwidthUsedMbps",
        "label": "CDN Average Bandwidth Used Over Time"
    },

    "CDN Average Last Mile Round Trip Time": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "These are the only fields we are interested in for this search.",
            "Sort our results based on time and include all results (large lookups.)",
            "Calculate the bandwidth used and convert it to MBps.",
            "Chart our average bandwidth, in 1 minute buckets, over time. We used fixedrange=false since this is data from a lookup."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| convert timeformat=\"%Y-%m-%d %T\" mktime(_time) AS _time \n| fields _time messageBytes netPerfdownloadTime \n| sort 0 _time \n| eval bandwidthUsedMbps = ((messageBytes/netPerfdownloadTime)*1000/1024/128) \n| timechart fixedrange=false span=1m avg(bandwidthUsedMbps) AS avgBandwidthUsedMbps",
        "label": "CDN Average Last Mile Round Trip Time"
    },

    "CDN High Latency Edge Networks": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "",
            "These are the only fields we are interested in for this search.",
            "Use the iplocation command to enrich our dataset with geodata.",
            "Fill unknown City values with Unknown value.",
            "Fill unknown Region values with Unknown value.",
            "Create a new field that will be an identifier for the edge location.",
            "Calculate the average response time for the data set by the Hosting Region",
            "",
            "",
            "Sort by the highest response time",
            "Make the results more human friendly."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(_time) AS _time \n| sort 0 _time \n| fields _time responseTime requestClientIp \n| iplocation requestClientIp \n| eval City=case(City==\"\",\"Unknown\",1=1,City) \n| eval Region=case(Region==\"\",\"Unknown\",1=1,Region) \n| eval HostingEdge = Region.\" - \".Country \n| stats avg(responseTime) AS avgResponseTime by HostingEdge \n| eval \"Average Response Time\"=round(avgResponseTime,3) \n| rename HostingEdge AS \"Edge Hosting Region\"\n| sort - \"Average Response Time\" \n| fields \"Edge Hosting Region\" \"Average Response Time\"",
        "label": "CDN High Latency Edge Networks"
    },

    "CDN - Top 5 Delivered Content Customers by Requests": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "",
            "These are the only fields we are interested in for this search.",
            "Use the iplocation command to enrich our dataset with geodata.",
            "Fill unknown City values with Unknown value.",
            "Fill unknown Region values with Unknown value.",
            "Create a new field that will be an identifier for the edge location.",
            "Calculate the average response time for the data set by the Hosting Region",
            "",
            "",
            "Sort by the highest response time",
            "Make the results more human friendly."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| fields cp \n| lookup cdn_contentproviders contentProviderCode AS cp \n| stats count by contentProviderDescription \n| sort - count \n| head 5",
        "label": "CDN - Top 5 Delivered Content Customers by Requests"
    },

    "CDN - Revenue Generated by Requests": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "",
            "These are the only fields we are interested in for this search.",
            "Use the iplocation command to enrich our dataset with geodata.",
            "Fill unknown City values with Unknown value.",
            "Fill unknown Region values with Unknown value.",
            "Create a new field that will be an identifier for the edge location.",
            "Calculate the average response time for the data set by the Hosting Region",
            "",
            "",
            "Sort by the highest response time",
            "Make the results more human friendly."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| convert timeformat=\"%Y-%m-%d %T\" mktime(_time) AS _time \n| sort 0 _time \n| fields _time cp requestClientIp status \n| lookup cdn_contentproviders contentProviderCode AS cp OUTPUT contentProviderName \n| iplocation requestClientIp allfields=true \n| fields _time cp Continent contentProviderName status \n| lookup cdn_content_costs billableRegion AS Continent OUTPUT costPerRequest \n| timechart fixedrange=false span=1h sum(costPerRequest) AS billableRequests",
        "label": "CDN - Revenue Generated by Requests"
    },

    "CDN - Total Revenue Generated": {
        "prereqs": [
            {
                "test": "| inputlookup cdn_general_operations | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamps..",
            "This will make sure our timestamp is in true timestamp format and not text.",
            "Sort our timestamp and include all results.",
            "These are the only fields we are interested in for this search.",
            "Enrich our events with the human readable name of the content provider.",
            "Use the iplocation command with the allfields=true option, which provides a continent field we need later.",
            "Narrow our fields down to those of interest.",
            "Convert our messagebytes value to megabytes to calculate revenue.",
            "Enrich our data with billable rates for the transfers and associate a cost to each request, per geo-region.",
            "Calculate the transfer revenue.",
            "Use timechart to calculate a total sum of our xferRevenue and our total cost per request. Use fixedrange=false here because this is from a lookup."
        ],
        "value": "| inputlookup cdn_general_operations \n| eval time=strptime(_time,\"%Y-%m-%d %H:%M:S\") \n| convert timeformat=\"%Y-%m-%d %T\" mktime(_time) AS _time \n| sort 0 _time \n| fields _time cp requestClientIp status messageBytes \n| lookup cdn_contentproviders contentProviderCode AS cp OUTPUT contentProviderName \n| iplocation requestClientIp allfields=true \n| fields _time cp Continent contentProviderName status messageBytes \n| eval megabytesTransferred=((messageBytes/pow(1024,2) )) \n| lookup cdn_content_costs billableRegion AS Continent OUTPUT costPerMBTransferred costPerRequest \n| eval xferRevenue = costPerMBTransferred * megabytesTransferred \n| timechart fixedrange=false span=1h eval(sum(xferRevenue) + sum(costPerRequest)) AS totalRevenue",
        "label": "CDN - Total Revenue Generated"
    },

    "General Call Metrics - Daily Estimated Call Revenue": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Set our timestamp..",
            "Enrich our events with the Call Disposition.",
            "Search for Answered or Billable calls.",
            "Use rex against the dst field to extract a dstCountry Code.",
            "Lookup and enrich our country code. Add a country name, iso code, and billable rates.",
            "Narrow our fields down.",
            "Use the convert command to get a easier math friendly number for duration.",
            "Calculate billables minutes based on our duration.",
            "Round our minute value to the near whole number.",
            "Calculate our total duration, minus one minute.",
            "Calculate the total billable rate per call",
            "Summate the total billable and display it as a Single Value."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=\"ANSWERED\" OR billable > 0 \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode rateFirstMinute rateMinute \n| fields _time accountcode src billable dstCountryCode rate* \n| convert dur2sec(billable) AS calculatedBillableS \n| eval billableMinutes = calculatedBillableS / 60 \n| eval billableMinutes = ceiling(billableMinutes) \n| eval billableMinusOne = billableMinutes - 1 \n| eval totalBillable = rateMinute + (billableMinusOne * rateMinute) \n| stats sum(totalBillable) as CallRevenue",
        "label": "General Call Metrics - Daily Estimated Call Revenue"
    },


    "General Call Disposition Metrics": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Enrich our disposition to get a human readable message.",
            "Use stats to create a count of Descriptions by the Disposition.",
            "Humanize our fields.. ",
            "Format our table",
            "Give a more contextual Description for the Congested value.",
            "Sort the results by highest count."
        ],
        "value": "| inputlookup cdr_logs \n| lookup cdr_disposition_mapping disposition \n| stats count values(description) AS Description by disposition \n| rename disposition AS Disposition count AS Count \n| table Description Disposition Count \n| eval Description=if(match(Disposition,\"CONGESTED\"),\"Route Error\",Description) \n| sort - Count",
            "label": "General Call Disposition Metrics"
    },

    "Failed Call Metrics - Simple": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Enrich our disposition to get a human readable message.",
            "Search for failed call logs.",
            "Use stats to create a count of Descriptions by the Disposition.",
            "Humanize our fields.. ",
            "Format our table",
            "Give a more contextual Description for the Congested value.",
            "Sort the results by highest count."
        ],
        "value": "| inputlookup cdr_logs \n| lookup cdr_disposition_mapping disposition \n| search disposition=\"FAILED\" OR disposition=\"CONGESTED\" \n| stats count values(description) AS Description by disposition \n| rename disposition AS Disposition count AS Count \n| table Description Disposition Count \n| eval Description=if(match(Disposition,\"CONGESTED\"),\"Route Error\",Description) \n| sort - Count",
        "label": "Failed Call Metrics - Simple"
    },

    "Failed Call Metrics - Advanced": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Set our timestamp field from our lookup.",
            "Enrich our data with a mapping of error codes to a message.",
            "Search for our definition of failed calls..",
            "Add a more descriptive Description for our Congested Disposition message.",
            "Extract a field for our source country from the caller / source.",
            "Extract a field for our destintation country from the callee / destination.",
            "Add country code and country code and country name to our search results.",
            "",
            "Make the fields a bit more human friendly for a report."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=FAILED OR disposition=CONGESTED \n| eval Description=if(match(disposition,\"CONGESTED\"),\"Route Error\",description) \n| rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| table _time src dst dstCountryCode Description disposition \n| rename _time AS Time src AS \"Source #\" dst AS \"Destination #\" disposition AS Disposition dstCountryCode AS \"Destination Country\"",
        "label": "Failed Call Metrics - Advanced"
    },

    "Failed Call Metrics - Geo Stats": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Set our timestamp field..",
            "Enrich our call disposition status codes with more understandable reason..",
            "Search for failed calls ",
            "Update the description field for a specific error, in this case Routing Error.",
            "Extract a country code from the dialed number. We assume the country code preceeds a 10 digit local number.",
            "Enrich the logs by adding a Country Name based on the dstCountry field we extracted.",
            "Calculate the count by the dstCountryName",
            "Use the geomap feature to map the count."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=FAILED OR disposition=CONGESTED \n| eval Description=if(match(disposition,\"CONGESTED\"),\"Route Error\",description) \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName \n| stats count by dstCountryName  \n| geom geo_countries allFeatures=true featureIdfield=dstCountryName",
        "label": "Failed Call Metrics - Geo Stats"
    },

    "Failed Call Metrics - By Destination and Gateway": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=FAILED OR disposition=CONGESTED \n| eval Description=if(match(disposition,\"CONGESTED\"),\"Route Error\",description) \n| rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| table src dst dstCountryCode partyBiD disposition Description _time \n| stats count values(dst) AS Destination values(disposition) AS Disposition values(Description) AS Description values(_time) as Time by partyBiD dst \n| rename partyBiD AS \"Routed Path\" \n| table Time Destination Description \"Routed Path\" count",
        "label": "Failed Call Metrics - By Destination and Gateway"
    },

    "General Call Metrics - Geo Stats": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=\"ANSWERED\" OR disposition=\"BUSY\" \n| rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| stats count by dstCountryName \n| geom geo_countries allFeatures=true featureIdfield=dstCountryName",
        "label": "General Call Metrics - Geo Stats"
    },

    "General Call Metrics - Top Destination Countries": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName \n| top limit=10 dstCountryName",   
        "label": "General Call Metrics - Top Destination Countries"
    },

    "General Call Metrics - Least Called Countries": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| rare limit=10 dstCountryName",
        "label": "General Call Metrics - Least Called Countries"
    },

    "General Call Metrics - Top Outbound Callers": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start | rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| top dstCountryName by src \n| rename src AS \"Caller\" dstCountryName AS \"Destinaton Country\" count as Count",
        "label": "General Call Metrics - Top Outbound Callers"
    },

    "General Call Metrics - Top Call Durations by Destination": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=\"ANSWERED\" OR disposition=\"BUSY\" \n| rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| fields src dst dstCountryName duration \n| stats count list(dst) AS dst list(dstCountryName) as dstCountryName by duration src \n| rename duration AS \"Call Duration\" src AS \"Caller\" dst AS \"Called Number\" dstCountryName AS \"Destination Country\" \n| sort - \"Call Duration\"",
        "label": "General Call Metrics - Top Call Durations by Destination"
    },

    "General Call Metrics - Shortest Call Durations by Destination": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=\"ANSWERED\" OR disposition=\"BUSY\" \n| rex field=src \"(?<srcCountry>\\d+)(?=\\d{10})\" \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| fields src dst dstCountryName duration \n| stats count list(dst) AS dst list(dstCountryName) as dstCountryName by duration src \n| rename duration AS \"Call Duration\" src AS \"Caller\" dst AS \"Called Number\" dstCountryName AS \"Destination Country\" \n| sort \"Call Duration\"",
        "label": "General Call Metrics - Shortest Call Durations by Destination"
    },

    "General Call Metrics - Cumulative Minutes by Caller": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Set our timestamp field..",
            "Enrich our data with the call disposition mapping...",
            "Search for calls that are billable.. In our case Answered, or billable greater then 0.. ",
            "We need to extract a country code from the dialed number We use the assumption that the country code is what preceeds a 10 digit number.",
            "Enrich based on the country code extracted field and add new fields.",
            "Restrict to only the fields we are interested in..",
            "Convert our call duration to a more math friendly number",
            "Run our values for accountcode and dstcountrycode through stats by the SRC. In the same stats pipeline, we calculate our billable minutes based on the summated call duratioms, by SRC.",
            "Take our multivalued field and convert it to single values.",
            "Make it more human readable.",
            "Output a table..",
            "Sort on our Billable Minutes."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| lookup cdr_disposition_mapping disposition \n| search disposition=\"ANSWERED\" OR billable > 0 \n| rex field=dst \"(?<dstCountry>\\d+)(?=\\d{10})\" \n| lookup cdr_country_codes phoneCode AS dstCountry OUTPUTNEW countryName as dstCountryName ISO2 AS dstCountryCode \n| fields _time accountcode src billable dstCountryCode \n| convert dur2sec(billable) AS calculatedBillableS \n| stats values(accountcode) AS Account values(dstCountryCode) AS CalledCountries sum(eval(round((calculatedBillableS/60),0))) AS BillableMinutes by src \n| nomv CalledCountries \n| rename src AS \"Caller\" BillableMinutes AS \"Billable Minutes\" \n| table Account Caller CalledCountries \"Billable Minutes\" \n| sort - \"Billable Minutes\"",
        "label": "General Call Metrics - Cumulative Minutes by Caller"
    },
    
    "General Call Metrics - Session Tracking": {
        "prereqs": [
            {
                "test": "| inputlookup cdr_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup cdr_logs \n| eval _time = start \n| table _time accountcode channel src dst duration partyBiD \n| rex field=channel \".*-(?<sessionId>\\d+$)\" \n| search duration > 0 \n| convert dur2sec(duration) AS CallDuration \n| eval CallDuration=round((CallDuration/60),0).\" minutes\" \n| stats count values(sessionId) AS SessionID values(accountcode) AS AccountID values(dst) AS DestinationNumber values(_time) AS DialTime list(CallDuration) AS CallDuration by src dst \n| lookup cdr_account_mappings accountCode AS AccountID OUTPUT accountName billingState \n| rename src AS SourceNumber \n| table AccountID accountName billingState SourceNumnber DestinationNumber SessionID CallDuration DialTime",
        "label": "General Call Metrics - Session Tracking"
    },

    "Security Auditing - Badge Monitoring": {
        "prereqs": [
            {
                "test": "| inputlookup physical_card_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "",
            "Enrich our data...",
            "Enrich our data... ",
            "Here we will search for a specific Employee Identifier.",
            "Narrow our interesting fields down a bit..",
            "",
            "",
            "Make this more Human Readable.."
        ],
        "value": "| inputlookup physical_card_logs \n| lookup physical_card_error_codes errorCode OUTPUTNEW status \n| lookup physical_card_mapping readerID AS badgereaderId OUTPUTNEW description \n| lookup physical_card_user_mapping cardId AS badgeId OUTPUTNEW firstName lastName emailAddress employeeId note officeId \n| search employeeId=\"25020002\" \n| fields - badgereaderId,envAlarm,errorCode,powerStatus \n| eval fullName = firstName+\" \"+lastName \n| fields _time badgeId employeeId fullName officeId description status note \n| rename badgeId AS \"Badge ID #\" employeeId AS \"Employee Number\" fullName AS \"Employee Name\" officeId AS \"Home Office\" description AS \"Card Reader Location\" status AS \"Read Status\" note AS \"Additional Notes..\"",
                "label": "Security Auditing - Badge Monitoring"
    },

    "Security Auditing - Secure Facilities": {
        "prereqs": [
            {
                "test": "| inputlookup physical_card_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Enrich our data...",
            "Enrich our data... ",
            "Perform some statistical analysis on the Room, Status of the Reader, and the Badge.",
            "For this example, we mask Internal Employees Id's and Customer's Badges.",
            "Figure out the direction of the badge read based on the actual card reader.",
            "Match our room and give it a more human friendly name.",
            "Select our fields for reporting.",
            "Bit more of clean up..",
            "",
            "Can you read epoch? Convert this to readable form."
        ],
        "value": "| inputlookup physical_card_logs \n| lookup physical_card_mapping readerID AS badgereaderId OUTPUTNEW description active \n| lookup physical_card_user_mapping cardId AS badgeId \n| search description=\"LV-DC-2-DC-003-*\" \n| stats count list(description) AS Room list(status) AS Status list(badgeId) AS BadgeID list(employeeId) AS userId by _time \n| eval Personnel=if(match(userId,\"-\"),\"Customer Card\",\"Splunk Datacenter Staff\") \n| eval Direction=case(match(Room,\"-in\"),\"Ingress\",match(Room,\"-out\"),\"Egress\") \n| eval Room=case(match(Room,\"LV-DC-2-DC-003-\"),\"Secure Room - 3\") \n| fields _time Room Personnel Direction \n| rename _time AS \"Time\" \n| convert ctime(Time)",
              "label": "Security Auditing - Secure Facilities"
    },

    "Security Auditing - Abnormal Failures": {
        "prereqs": [
            {
                "test": "| inputlookup physical_card_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Enrich our data with reader status codes..",
            "Enrich our data with reader locations and status... ",
            "Enrich our data with card / user information.",
            "Make the first and name a single field.",
            "Select only fields of relevance for us.",
            "Search for denied OR successful reads.",
            "Use streamstats here to keep track of the previous events, and change on status change. This will track our reader.",
            "Search where our count > 1",
            "Set our span to five minutes.",
            "Get our aggregates for the badges, location, and name by time.",
            "Search where our count > 1",
            "Humanize fields.",
            "Can you read epoch? I can't.. humanize our timestamp.",
            "Format for reporting."
        ],
        "value": "| inputlookup physical_card_logs \n| lookup physical_card_error_codes errorCode OUTPUTNEW status \n| lookup physical_card_mapping readerID AS badgereaderId OUTPUTNEW description active \n| lookup physical_card_user_mapping cardId AS badgeId \n| eval fullName=firstName+\" \"+lastName \n| fields _time badgeId description fullName status \n| search status=\"ACCESS-DENIED\" OR status=\"READ-SUCCESS\" \n| streamstats count reset_on_change=true window=2 by description \n| search (count > 1) AND status=\"ACCESS-DENIED\" \n| bin span=5m _time \n| stats count list(badgeId) AS Badge list(description) AS Location list(fullName) as Name by _time \n| where count > 1 \n| rename _time AS Time \n| convert ctime(Time) \n| table Time Location Badge Name",
        "label": "Security Auditing - Abnormal Failures"
    },

    "Security Auditing - Environmental Check": {
        "prereqs": [
            {
                "test": "| inputlookup physical_card_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Enrich our data...",
            "Enrich our data... ",
            "Reduce our data set to only our interesting fields for this example.",
            "Filter for only FIRE or POWER events."
                    ],
        "value": "| inputlookup physical_card_logs \n| lookup physical_card_error_codes errorCode OUTPUTNEW status \n| lookup physical_card_mapping readerID AS badgereaderId OUTPUTNEW description\n| fields _time badgereaderId description envAlarm errorCode powerStatus status \n| search envAlarm=\"FIRE\" OR envAlarm=\"POWER\"",        
        "label": "Security Auditing - Environmental Check"
    },
    
    "Security Auditing - Environmental Reporting": {
        "prereqs": [
            {
                "test": "| inputlookup physical_card_logs.csv | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Enrich our data...",
            "Enrich our data... ",
            "Filter for only FIRE or POWER events.",
            "Sort by time, we need to make sure our data set is in order..",
            "Filter through events by description, and keep track of when the last reader was seen",
            "Calculate a duration between related events",
            "",
            "Fill null numeric values with a 0 to make sorting easier..",
            "Humanize the Events..",
            "Take our relevant fields and make a report friendly view.."
                    ],
        "value": "| inputlookup physical_card_logs \n| lookup physical_card_mapping readerID AS badgereaderId OUTPUTNEW description \n| lookup physical_card_error_codes errorCode OUTPUT status \n| search envAlarm=\"FIRE\" OR envAlarm=\"POWER\" \n| sort _time \n| streamstats window=0 current=false latest(_time) AS previousEventTime latest(status) AS previousStatus BY description \n| eval duration = _time - previousEventTime \n| rename status AS currentStatus \n| fillnull value=0 duration \n| eval envAlarm=case(match(envAlarm,\"FIRE\"),\"Fire Alarm Detected in Zone\",match(envAlarm,\"POWER\"),\"Power Event Detected in Zone\") \n| fields _time description currentStatus duration envAlarm \n| rename description AS \"Reader Location\" currentStatus AS \"Lock Status\" envAlarm AS \"Alarm\" \n| convert ctime(previousEventTime) \n| where duration > 0 \n| rename duration AS \"Duration of Alarm (seconds)\" _time AS \"Time Cleared\" \n| convert ctime(\"Time Cleared\") \n| table Alarm \"Reader Location\" \"Lock Status\" \"Duration of Alarm (seconds)\" \"Time Cleared\"",       
        "label": "Security Auditing - Environmental Reporting"
    },

    "WIFI AP Association": {
        "prereqs": [
            {
                "test": "| inputlookup telco_wifi_mapping | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp...",
            " ",
            "Chart the count of Access PointIDs over 15 minute buckets.",
            "Formatting with a lookup, remove for real data source."
                    ],
        "value": "| inputlookup telco_wifi_mapping \n| eval _time=strptime(accessTime, \"%Y-%m-%d %H:%M:%S\") \n| sort - _time \n| timechart count fixedrange=false span=15m by apID",
       "label": "WIFI AP Association"
    },

    "WIFI AP Access Duration Stats": {
        "prereqs": [
            {
                "test": "| inputlookup telco_wifi_mapping | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp...",
            " ",
            "Convert our timestamps to EPOCH times, which makes numeric operations easier.",
            "Calculate our Average / Maximum / Minimum connection durations.",
            "Convert to minutes",
            "Convert to minutes",
            "In most cases this is 0, or few seconds, but show in minutes.",
            "Make this more report friendly for the humans."
                    ],
        "value": "| inputlookup telco_wifi_mapping \n| eval _time=strptime(accessTime, \"%Y-%m-%d %H:%M:%S\") \n| sort _time \n| convert timeformat=\"%Y-%m-%d %T\" mktime(accessTime) AS accessTime mktime(accessDisconnectTime) AS accessDisconnectTime \n| eval accessDuration = accessDisconnectTime-accessTime \n| stats avg(accessDuration) as avgAccessDur max(accessDuration) as maxAccessdur min(accessDuration) as minAccessdur by apID \n| eval avgAccessDur=round(avgAccessDur/60,2) \n| eval maxAccessdur=round(maxAccessdur/60,2) \n| eval minAccessdur=round(minAccessdur/60,2) \n| rename apID AS \"WIFI AP Name\" avgAccessDur AS \"Average Duration (Minutes)\" maxAccessdur AS \"Maximum Duration (Minutes)\" minAccessdur AS \"Minimum Duration (Minutes)\"",
        "label": "WIFI AP Access Duration Stats"
    },
    
    "WIFI AP Geostats Access by Time": {
        "prereqs": [
            {
                "test": "| inputlookup telco_wifi_mapping | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp...",
            " ",
            "Chart the count of Access PointIDs over 15 minute buckets.",
            "Formatting with a lookup, remove for real data source."
                    ],
        "value": "| inputlookup telco_wifi_mapping \n| eval _time=strptime(accessTime, \"%Y-%m-%d %H:%M:%S\") \n| sort - _time \n| timechart count fixedrange=false span=15m by apID",
       "label": "WIFI AP Geostats Access by Time"
    },

    "WIFI AP Networks Users Connect To": {
        "prereqs": [
            {
                "test": "| inputlookup telco_wifi_mapping | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp...",
            "Sort our time..",
            "Here we start run stats against our network connections by Access Point and Network",
            "Running stats here again gives us a per AP and per Network connection list.",
            "Make this more human readable."
                    ],
        "value": "| inputlookup telco_wifi_mapping \n| eval _time=strptime(accessTime, \"%Y-%m-%d %H:%M:%S\") \n| sort - _time \n| stats count values(apInfoNetwork) AS apInfoNetworks by apID apInfoNetwork \n| stats list(apInfoNetwork) AS apInfoNetwork list(apID) as apID list(count) as Count \n| rename apInfoNetwork AS \"Connected Network\" apID AS \"Access Point Connected\" Count AS \"Connection Count\"", 
        "label": "WIFI AP Networks Users Connect To"
    },

    "WAP Potential Abnormal Connectivity": {
        "prereqs": [
            {
                "test": "| inputlookup telco_wifi_mapping | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp...",
            "Convert time fields to epoch so we can do some math...",
            "Convert time fields to epoch so we can do some math...",
            "Calculate a duration.. ",
            "Use only relevant fields..",
            "Convert all our epoch times back to a human readable view",
            "Calulate the values of our accessTime, disconnectTime and durations by userHash and time.",
            "Look for count > 1, which indicates multiple WAP associations.",
            "Make our fields more human readable.",
            "Arrange our fields in a more friendly format.",
            "Sort our results based on earliest time.",
            "Remove ugly field(s)."
                    ],
        "value": "| inputlookup telco_wifi_mapping \n| eval _time=strptime(accessTime, \"%Y-%m-%d %H:%M:%S\") \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(accessDisconnectTime) AS disconnectTime \n| convert timeformat=\"%Y-%m-%d %H:%M:%S\" mktime(accessTime) AS accessTime \n| eval duration = disconnectTime - accessTime \n| fields _time userHash apID accessTime disconnectTime duration \n| convert ctime(*Time) \n| stats count values(accessTime) as accessTime list(disconnectTime) AS disconnectTime list(duration) AS duration list(apID) as apID by userHash _time \n| search count > 1 \n| rename userHash AS User accessTime AS \"WAP Access Time\" disconnectTime AS \"Disconnect Time\" duration AS Duration apID AS \"WAP Name\" \n| fields User \"WAP Name\" \"WAP Access Time\" \"Disconnect Time\" Duration \n| sort _time \n| fields - _time",
        "label": "WAP Potential Abnormal Connectivity"
    },

    "WIFI AP Access Users Top Cities": {
        "prereqs": [
            {
                "test": "| inputlookup telco_wifi_mapping | stats count  ",
                "field": "count",
                "greaterorequalto": 1,
                "resolution": "Verify that lookups installed with Splunk Essentials for Telco is present",
                "name": "track_application_usage lookup file"
            }
        ],
        "description": [
            "First we pull in our demo dataset.",
            "Format our timestamp...",
            "Sort our time..",
            "We just want our known cities in this search. ",
            "Find our 10 top cities.",
            "Sort by count to get our top cities",
            "Return the top 10 results."
                    ],
        "value": "| inputlookup telco_wifi_mapping \n| eval _time=strptime(accessTime, \"%Y-%m-%d %H:%M:%S\") \n| sort - _time \n| where userCity != \"UNKNOWN\" \n| stats count BY userCity \n| sort - count \n| head 10",
        "label": "WIFI AP Access Users Top Cities"
    }
}
